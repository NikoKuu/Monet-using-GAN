{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f675795-d1ad-4cbb-b8f1-f51c87f1b3dc",
   "metadata": {},
   "source": [
    "# Run inference in Keras 3 with the OpenVINO™ IR backend\n",
    "\n",
    "Starting with release 3.8, [Keras](https://github.com/keras-team/keras) provides native integration with the OpenVINO backend for accelerated inference. This integration enables you to leverage OpenVINO performance optimizations directly within the Keras workflow, enabling faster inference on OpenVINO supported hardware.\n",
    "\n",
    "\n",
    "In this tutorial, we will show how to run inference of an end-to-end [BERT model for classification tasks](https://www.kaggle.com/models/keras/bert/) using the OpenVINO backend.\n",
    "\n",
    "\n",
    ">**Note**: The OpenVINO backend may currently lack support for some operations. This will be addressed in upcoming Keras releases as operation coverage is being expanded.\n",
    "\n",
    ">**Note**: The `tensorflow-text` package [isn't provided for Windows after version 2.10](https://github.com/tensorflow/text#a-note-about-different-operating-system-packages). `tensorflow-text==2.16.1` - the last version that supports `macOS x86_64`, but it doesn't support `macOS arm` and `python3.12`. Since tensorflow-text==2.17.0 supports `macOS arm`, since `2.18.1` - `python12`. This package is required for `BertTokenizer`.\n",
    "\n",
    "\n",
    "#### Table of contents:\n",
    "\n",
    "- [Prerequisites](#Prerequisites)\n",
    "- [Load the model with the OpenVINO backend and inference](#Load-the-model-with-the-OpenVINO-backend-and-inference)\n",
    "- [Sentiment Classification Example](#Sentiment-Classification-Example)\n",
    "\n",
    "\n",
    "### Installation Instructions\n",
    "\n",
    "This is a self-contained example that relies solely on its own code.\n",
    "\n",
    "We recommend  running the notebook in a virtual environment. You only need a Jupyter server to start.\n",
    "For details, please refer to [Installation Guide](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/README.md#-installation-guide).\n",
    "\n",
    "<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=5b5a4db0-7875-4bfb-bdbd-01698b5b1a77&file=notebooks/keras-with-openvino-backend/keras-with-openvino-backend.ipynb\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814330bf-625d-4c19-8ee9-a0f8d21c3fab",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4b9c29-820e-4fa0-abdc-d9618362b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"openvino>=2025.0.0\"\n",
    "%pip install -q \"keras>=3.8\" \"keras-hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b7aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib.util>:207: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "\n",
    "if not Path(\"notebook_utils.py\").exists():\n",
    "    r = requests.get(\n",
    "        url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    "    )\n",
    "\n",
    "    open(\"notebook_utils.py\", \"w\").write(r.text)\n",
    "\n",
    "\n",
    "# Read more about telemetry collection at https://github.com/openvinotoolkit/openvino_notebooks?tab=readme-ov-file#-telemetry\n",
    "from notebook_utils import collect_telemetry\n",
    "\n",
    "collect_telemetry(\"keras-with-openvino-backend.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef034f42-b4cf-4cdf-b02d-44954342b3a6",
   "metadata": {},
   "source": [
    "## Load the model with the OpenVINO backend and inference\n",
    "[back to top ⬆️](#Table-of-contents:)\n",
    "\n",
    "Keras provides list of pretrained for general purposes models that can be used for fine-tuning on specific task.\n",
    "\n",
    "We will use the BERT model using the [`BertTextClassifier`](https://keras.io/keras_hub/api/base_classes/text_classifier/#textclassifier-class) class. OpenVINO API provides only inference capabilities, which means that before moving to the OpenVINO backend, you need to train the model on your own data using one of the backends that supports training. Once your model training process is finished, you can move to OpenVINO for inference speedup. Here are the general steps you need for that:\n",
    "\n",
    "    1. Specify the backend using an environment variable.\n",
    "    2. Create a model instance.\n",
    "    3. Run model prediction.\n",
    "\n",
    "To switch to the OpenVINO backend in Keras 3, set the `KERAS_BACKEND` environment variable to `openvino` or specify the backend in the local configuration file at `~/.keras/keras.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2c9140-361f-4135-a463-7b9a494d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"openvino\"\n",
    "import numpy as np\n",
    "import keras_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fa6ca-e3b2-42e1-98a9-af95e1ef2155",
   "metadata": {},
   "source": [
    "Create a model instance. Take a model from [KerasHub](https://keras.io/keras_hub/presets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1958a3-89c9-4fb9-b505-7f4129c274b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'keras_hub.src.models.bert.bert_tokenizer.BertTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.bert.bert_tokenizer', 'class_name': 'BertTokenizer', 'config': {'name': 'bert_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'vocabulary': None, 'sequence_length': None, 'lowercase': True, 'strip_accents': False, 'split': True, 'suffix_indicator': '##', 'oov_token': '[UNK]', 'special_tokens': None, 'special_tokens_in_strings': False}, 'registered_name': 'keras_hub>BertTokenizer'}.\n\nException encountered: Error when deserializing class 'BertTokenizer' using config={'name': 'bert_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'vocabulary': None, 'sequence_length': None, 'lowercase': True, 'strip_accents': False, 'split': True, 'suffix_indicator': '##', 'oov_token': '[UNK]', 'special_tokens': None, 'special_tokens_in_strings': False}.\n\nException encountered: BertTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\ops\\operation.py:234\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\models\\bert\\bert_tokenizer.py:76\u001b[0m, in \u001b[0;36mBertTokenizer.__init__\u001b[1;34m(self, vocabulary, lowercase, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_special_token(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SEP]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlowercase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlowercase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\tokenizers\\word_piece_tokenizer.py:342\u001b[0m, in \u001b[0;36mWordPieceTokenizer.__init__\u001b[1;34m(self, vocabulary, sequence_length, lowercase, strip_accents, split, split_on_cjk, suffix_indicator, oov_token, special_tokens, special_tokens_in_strings, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput dtype must be an integer type or a string. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    340\u001b[0m     )\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m oov_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\tokenizers\\tokenizer.py:70\u001b[0m, in \u001b[0;36mTokenizer.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, TOKENIZER_CONFIG_FILE)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_assets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\layers\\preprocessing\\preprocessing_layer.py:10\u001b[0m, in \u001b[0;36mPreprocessingLayer.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 10\u001b[0m     \u001b[43massert_tf_libs_installed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\tensor_utils.py:254\u001b[0m, in \u001b[0;36massert_tf_libs_installed\u001b[1;34m(symbol_name)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires `tensorflow` and `tensorflow-text` for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext processing. Run `pip install tensorflow-text` to install \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth packages or visit https://www.tensorflow.org/install\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `tensorflow-text` is already installed, try importing it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min a clean python session. Your installation may have errors.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasHub uses `tf.data` and `tensorflow-text` to preprocess text \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon all Keras backends. If you are running on Jax or Torch, this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstallation does not need GPU support.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: BertTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\ops\\operation.py:236\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'BertTokenizer' using config={'name': 'bert_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'vocabulary': None, 'sequence_length': None, 'lowercase': True, 'strip_accents': False, 'split': True, 'suffix_indicator': '##', 'oov_token': '[UNK]', 'special_tokens': None, 'special_tokens_in_strings': False}.\n\nException encountered: BertTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBertTextClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_preset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert_base_en_uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\models\\task.py:198\u001b[0m, in \u001b[0;36mTask.from_preset\u001b[1;34m(cls, preset, load_weights, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Specifically for classifiers, we never load task weights if\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# num_classes is supplied. We handle this in the task base class because\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# it is the same logic for classifiers regardless of modality (text,\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# images, audio).\u001b[39;00m\n\u001b[0;32m    197\u001b[0m load_task_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:670\u001b[0m, in \u001b[0;36mKerasPresetLoader.load_task\u001b[1;34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, load_weights, load_task_weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# If there is no `task.json` or it's for the wrong class delegate to the\u001b[39;00m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;66;03m# super class loader.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset, TASK_CONFIG_FILE):\n\u001b[1;32m--> 670\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m     task_config \u001b[38;5;241m=\u001b[39m load_json(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset, TASK_CONFIG_FILE)\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(task_config), \u001b[38;5;28mcls\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:622\u001b[0m, in \u001b[0;36mPresetLoader.load_task\u001b[1;34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_backbone(\n\u001b[0;32m    619\u001b[0m         backbone_class, load_weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackbone_kwargs\n\u001b[0;32m    620\u001b[0m     )\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor_cls:\n\u001b[1;32m--> 622\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:708\u001b[0m, in \u001b[0;36mKerasPresetLoader.load_preprocessor\u001b[1;34m(self, cls, config_file, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_preprocessor\u001b[39m(\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file\u001b[38;5;241m=\u001b[39mPREPROCESSOR_CONFIG_FILE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    704\u001b[0m ):\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;66;03m# If there is no `preprocessing.json` or it's for the wrong class,\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# delegate to the super class loader.\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset, config_file):\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     preprocessor_json \u001b[38;5;241m=\u001b[39m load_json(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset, config_file)\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(preprocessor_json), \u001b[38;5;28mcls\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:636\u001b[0m, in \u001b[0;36mPresetLoader.load_preprocessor\u001b[1;34m(self, cls, config_file, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_preprocessor\u001b[39m(\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file\u001b[38;5;241m=\u001b[39mPREPROCESSOR_CONFIG_FILE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    629\u001b[0m ):\n\u001b[0;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a prepocessor layer from the preset.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m    By default, we create a preprocessor from a tokenizer with default\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m    arguments. This allow us to support transformers checkpoints by\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    only converting the backbone and tokenizer.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_missing_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\models\\preprocessor.py:201\u001b[0m, in \u001b[0;36mPreprocessor._add_missing_kwargs\u001b[1;34m(cls, loader, kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fill in required kwargs when loading from preset.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03mThis is a private method hit when loading a preprocessing layer that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mencoders.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_cls:\n\u001b[1;32m--> 201\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_converter\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39maudio_converter_cls:\n\u001b[0;32m    203\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_converter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_audio_converter(\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39maudio_converter_cls\n\u001b[0;32m    205\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:653\u001b[0m, in \u001b[0;36mKerasPresetLoader.load_tokenizer\u001b[1;34m(self, cls, config_file, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file\u001b[38;5;241m=\u001b[39mTOKENIZER_CONFIG_FILE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    652\u001b[0m     tokenizer_config \u001b[38;5;241m=\u001b[39m load_json(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset, config_file)\n\u001b[1;32m--> 653\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_serialized_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_preset_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    655\u001b[0m         tokenizer\u001b[38;5;241m.\u001b[39mload_preset_assets(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:725\u001b[0m, in \u001b[0;36mKerasPresetLoader._load_serialized_object\u001b[1;34m(self, config, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m config \u001b[38;5;241m=\u001b[39m set_dtype_in_config(config, dtype)\n\u001b[0;32m    724\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 725\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'keras_hub.src.models.bert.bert_tokenizer.BertTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.bert.bert_tokenizer', 'class_name': 'BertTokenizer', 'config': {'name': 'bert_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'vocabulary': None, 'sequence_length': None, 'lowercase': True, 'strip_accents': False, 'split': True, 'suffix_indicator': '##', 'oov_token': '[UNK]', 'special_tokens': None, 'special_tokens_in_strings': False}, 'registered_name': 'keras_hub>BertTokenizer'}.\n\nException encountered: Error when deserializing class 'BertTokenizer' using config={'name': 'bert_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'vocabulary': None, 'sequence_length': None, 'lowercase': True, 'strip_accents': False, 'split': True, 'suffix_indicator': '##', 'oov_token': '[UNK]', 'special_tokens': None, 'special_tokens_in_strings': False}.\n\nException encountered: BertTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support."
     ]
    }
   ],
   "source": [
    "bert = keras_hub.models.BertTextClassifier.from_preset(\n",
    "    \"bert_base_en_uncased\",\n",
    "    num_classes=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90642b50-c073-4010-bef4-89e4b4945b08",
   "metadata": {},
   "source": [
    "Run model prediction for raw string data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139429d-c714-47b9-804a-aa0de39dee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14641605,  0.33292952, -0.07132149,  0.2362039 ],\n",
       "       [ 0.14057046,  0.2972596 , -0.02436665,  0.29821312]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"The quick brown fox jumped.\", \"I forgot my homework.\"]\n",
    "\n",
    "bert.predict(x=features, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2bc93-c548-45a6-9ac6-cca303d5b63c",
   "metadata": {},
   "source": [
    "Preprocessed integer data. You can obtain this data using any tokenizer. In the previous example, the default tokenizer was used to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c21effe-b418-41e7-a236-373aa9d349d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03224922,  0.09847151,  0.32198498,  0.09585449],\n",
       "       [-0.03224922,  0.09847151,  0.32198498,  0.09585449]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {\n",
    "    \"token_ids\": np.ones(shape=(2, 12), dtype=\"int32\"),\n",
    "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]] * 2),\n",
    "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]] * 2),\n",
    "}\n",
    "\n",
    "bert = keras_hub.models.BertTextClassifier.from_preset(\n",
    "    \"bert_base_en_uncased\",\n",
    "    num_classes=4,\n",
    "    preprocessor=None,\n",
    ")\n",
    "\n",
    "predictions = bert.predict(x=features, batch_size=2)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ce7b6-7795-44ca-9be2-8524176f02be",
   "metadata": {},
   "source": [
    "## Sentiment Classification Example\n",
    "\n",
    "This example demonstrates how to use a pre-trained BERT model [bert_tiny_en_uncased_sst](https://www.kaggle.com/models/keras/bert/keras/bert_tiny_en_uncased_sst2) from [KerasHub](https://keras.io/keras_hub/presets/) to perform sentiment classification on a set of sentences. The model predicts whether each sentence expresses a positive or negative sentiment.\n",
    "\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2396fee9-22c8-479f-954b-dca91f0a4914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "Sentence                                           Sentiment\n",
      "-------------------------------------------------------------\n",
      "the movie was a complete waste of time.            negative\n",
      "the plot was predictable and boring.               negative\n",
      "i absolutely loved this movie, it was fantastic!   positive\n",
      "an excellent movie that i would highly recommend.  positive\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "bert = keras_hub.models.BertTextClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased_sst2\",\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "sentences = [\n",
    "    \"the movie was a complete waste of time.\",\n",
    "    \"the plot was predictable and boring.\",\n",
    "    \"i absolutely loved this movie, it was fantastic!\",\n",
    "    \"an excellent movie that i would highly recommend.\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    predictions = bert.predict([text])\n",
    "    probabilities = tf.nn.softmax(predictions, axis=1).numpy()\n",
    "    sentiment = np.argmax(probabilities, axis=1)[0]\n",
    "    sentiment_label = \"positive\" if sentiment == 1 else \"negative\"\n",
    "\n",
    "    return sentiment_label\n",
    "\n",
    "\n",
    "def display_results(results):\n",
    "    max_sentence_length = max(len(result[\"Sentence\"]) for result in results)\n",
    "    max_sentiment_length = max(len(result[\"Sentiment\"]) for result in results)\n",
    "\n",
    "    print(f\"{'Sentence':<{max_sentence_length}}  {'Sentiment':<{max_sentiment_length}}\")\n",
    "    print(\"-\" * (max_sentence_length + max_sentiment_length + 4))\n",
    "\n",
    "    for result in results:\n",
    "        sentence = result[\"Sentence\"]\n",
    "        sentiment = result[\"Sentiment\"]\n",
    "        print(f\"{sentence:<{max_sentence_length}}  {sentiment:<{max_sentiment_length}}\")\n",
    "\n",
    "\n",
    "results = []\n",
    "for sentence in sentences:\n",
    "    sentiment = get_sentiment(sentence)\n",
    "    results.append({\"Sentence\": sentence, \"Sentiment\": sentiment})\n",
    "\n",
    "\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789ff74",
   "metadata": {
    "test_replace": {
     "# %pip uninstall -q -y \"tensorflow-cpu\" tensorflow keras": "%pip uninstall -q -y \"tensorflow-cpu\" tensorflow keras\n%pip install tensorflow\n%pip uninstall -y tensorflow"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "# %pip uninstall -q -y \"tensorflow-cpu\" tensorflow keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "openvino_notebooks": {
   "imageUrl": "https://github.com/user-attachments/assets/f0f17c2e-0f00-49b5-8364-8d18f2cd06ff",
   "tags": {
    "categories": [
     "API Overview"
    ],
    "libraries": [],
    "other": [],
    "tasks": [
     "Text Classification"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
