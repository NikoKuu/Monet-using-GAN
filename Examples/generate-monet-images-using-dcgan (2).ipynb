{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monet using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:24.370717Z",
     "iopub.status.busy": "2025-03-23T19:47:24.369672Z",
     "iopub.status.idle": "2025-03-23T19:47:30.446912Z",
     "shell.execute_reply": "2025-03-23T19:47:30.445790Z",
     "shell.execute_reply.started": "2025-03-23T19:47:24.370612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import tensorflow_addons as tfa\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "if os.path.exists(r'C:\\Users\\kuusnin\\tempwork\\temp\\gan-getting-started'):\n",
    "    datapath = r'C:\\Users\\kuusnin\\tempwork\\temp\\gan-getting-started'\n",
    "elif os.path.exists(r'C:\\Users\\nikok\\Documents\\Monet using GAN'):\n",
    "    datapath = r'C:\\Users\\nikok\\Documents\\Monet using GAN'\n",
    "else:\n",
    "    datapath = r'/kaggle/input/gan-getting-started'\n",
    "print(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:30.449250Z",
     "iopub.status.busy": "2025-03-23T19:47:30.448645Z",
     "iopub.status.idle": "2025-03-23T19:47:30.462548Z",
     "shell.execute_reply": "2025-03-23T19:47:30.461383Z",
     "shell.execute_reply.started": "2025-03-23T19:47:30.449216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except Exception as e:\n",
    "    print(\"can't initialize tpu, using default, exception: \" + str(e))\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:30.464472Z",
     "iopub.status.busy": "2025-03-23T19:47:30.464121Z",
     "iopub.status.idle": "2025-03-23T19:47:33.299928Z",
     "shell.execute_reply": "2025-03-23T19:47:33.299119Z",
     "shell.execute_reply.started": "2025-03-23T19:47:30.464428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of the problem and data (5 pts)\n",
    "\n",
    "*Briefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:33.302210Z",
     "iopub.status.busy": "2025-03-23T19:47:33.301889Z",
     "iopub.status.idle": "2025-03-23T19:47:33.319829Z",
     "shell.execute_reply": "2025-03-23T19:47:33.318651Z",
     "shell.execute_reply.started": "2025-03-23T19:47:33.302180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "monet_files = os.listdir(os.path.join(datapath, 'monet_tfrec'))\n",
    "photo_files = os.listdir(os.path.join(datapath, 'photo_tfrec'))\n",
    "monet_filenames = [os.path.join(datapath, 'monet_tfrec', f) for f in monet_files]\n",
    "photo_filenames = [os.path.join(datapath, 'photo_tfrec', f) for f in photo_files]\n",
    "print(20*'*', 'Monet paintings', 20*'*')\n",
    "print('First filename:', monet_files[0], '\\nNumber of files:', len(monet_files))\n",
    "print(20*'*', 'Photos', 20*'*')\n",
    "print('First filename:', photo_files[0], '\\nNumber of files:', len(photo_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out the contents of the tfrec files\n",
    "\n",
    "From the code below we can see that each record/example contains three fields: \n",
    "* target: label of the image. Not needed in this work \n",
    "* image_name: name of the image\n",
    "* image: the actual image data\n",
    "\n",
    "Both of the data sets appear to have the same structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:33.321326Z",
     "iopub.status.busy": "2025-03-23T19:47:33.321009Z",
     "iopub.status.idle": "2025-03-23T19:47:36.644617Z",
     "shell.execute_reply": "2025-03-23T19:47:36.643514Z",
     "shell.execute_reply.started": "2025-03-23T19:47:33.321296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The following code is adapted from an answer from Microsoft Copilot\n",
    "import tensorflow as tf\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import json\n",
    "\n",
    "def iterate_record(dataset):\n",
    "    # Initialize a counter\n",
    "    record_count = 0\n",
    "    # Iterate through the dataset and count the records\n",
    "    for _ in dataset:\n",
    "        record_count += 1\n",
    "    print(f'Total number of records: {record_count}')\n",
    "    \n",
    "    # Iterate through the dataset and parse each record\n",
    "    for raw_record in dataset.take(1):  # Adjust the number to read more records\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        json_message = MessageToJson(example)\n",
    "        parsed_record = json.loads(json_message)\n",
    "        print(json.dumps(parsed_record, indent=2)[0:500])\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "print(20*'*', 'Monet paintings', 20*'*')\n",
    "raw_monet_dataset = tf.data.TFRecordDataset(monet_filenames)\n",
    "iterate_record(raw_monet_dataset)\n",
    "\n",
    "print('\\n' + 20*'*', 'Photos', 20*'*')\n",
    "raw_photo_dataset = tf.data.TFRecordDataset(photo_filenames)\n",
    "iterate_record(raw_photo_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse the data now since the structure of the tfrecord is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:36.646375Z",
     "iopub.status.busy": "2025-03-23T19:47:36.645984Z",
     "iopub.status.idle": "2025-03-23T19:47:36.768489Z",
     "shell.execute_reply": "2025-03-23T19:47:36.767379Z",
     "shell.execute_reply.started": "2025-03-23T19:47:36.646335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    example[\"image\"] = normalize(example[\"image\"])\n",
    "    return example\n",
    "\n",
    "def decode_image(tf_image):\n",
    "    return ((tf_image['image'].numpy() + 1) * 127.5).astype(int)\n",
    "\n",
    "monet_dataset = raw_monet_dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(32)\n",
    "photo_dataset = raw_photo_dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:36.770981Z",
     "iopub.status.busy": "2025-03-23T19:47:36.770183Z",
     "iopub.status.idle": "2025-03-23T19:47:36.952811Z",
     "shell.execute_reply": "2025-03-23T19:47:36.951920Z",
     "shell.execute_reply.started": "2025-03-23T19:47:36.770933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_monet = next(iter(monet_dataset))\n",
    "sample_photo = next(iter(photo_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T20:03:00.455957Z",
     "iopub.status.busy": "2025-03-23T20:03:00.455559Z",
     "iopub.status.idle": "2025-03-23T20:03:07.692047Z",
     "shell.execute_reply": "2025-03-23T20:03:07.691076Z",
     "shell.execute_reply.started": "2025-03-23T20:03:00.455929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dims(dataset, name):\n",
    "    dims = []\n",
    "    for data in dataset:\n",
    "        dims.append(data['image'].numpy().shape)\n",
    "    dims = np.array(dims)\n",
    "    print(f'Number of images in {name} dataset:', np.sum(dims[:,0]))\n",
    "    print(f'Unique shapes of the {name} data:', np.unique(dims[:,1:], axis=0))\n",
    "\n",
    "get_dims(monet_dataset, 'Monet')\n",
    "get_dims(photo_dataset, 'photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) â€” Inspect, Visualize and Clean the Data (15 pts)\n",
    "\n",
    "*Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T19:47:41.042025Z",
     "iopub.status.busy": "2025-03-23T19:47:41.041633Z",
     "iopub.status.idle": "2025-03-23T19:47:41.851514Z",
     "shell.execute_reply": "2025-03-23T19:47:41.850562Z",
     "shell.execute_reply.started": "2025-03-23T19:47:41.041993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "i = 0\n",
    "for i in range(4):\n",
    "    data = sample_monet['image']\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(np.array((data[i]+1)*127.5).astype(int))\n",
    "    i += 1\n",
    "for data in range(4):\n",
    "    data = sample_photo['image']\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(np.array((data[i]+1)*127.5).astype(int))\n",
    "    i += 1\n",
    "fig.suptitle('Examples of Monet and photos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check distribution of real image vs Monet paintings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T20:04:30.077240Z",
     "iopub.status.busy": "2025-03-23T20:04:30.076738Z",
     "iopub.status.idle": "2025-03-23T20:04:30.086188Z",
     "shell.execute_reply": "2025-03-23T20:04:30.084981Z",
     "shell.execute_reply.started": "2025-03-23T20:04:30.077198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(dataset, title):\n",
    "    rgb = []\n",
    "    rgb = [decode_image(d) for d in dataset.take(9)]\n",
    "    # for data in dataset:\n",
    "    #     rgb.append(decode_image(data))\n",
    "    rgb = np.array(rgb)\n",
    "    print(rgb.shape)\n",
    "    pic_channels = ['red', 'green', 'blue']\n",
    "    rgb_df = pd.DataFrame()\n",
    "    for i, clr in enumerate(pic_channels):\n",
    "        df = pd.DataFrame(rgb[:,:,:,:,i].ravel(), columns=['val'])\n",
    "        df['color'] = clr\n",
    "        rgb_df = pd.concat([rgb_df, df])\n",
    "    print('Minimum and maximmum values in ' + title + ' data: ', min(rgb_df.val), '&', max(rgb_df.val))\n",
    "    sns.histplot(rgb_df.sample(1000), x='val', hue='color', bins=30, multiple='dodge', color=['green', 'blue', 'red'])\n",
    "    plt.grid()\n",
    "    plt.title('Histogram of ' + title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T20:04:31.471185Z",
     "iopub.status.busy": "2025-03-23T20:04:31.470389Z",
     "iopub.status.idle": "2025-03-23T20:05:04.734538Z",
     "shell.execute_reply": "2025-03-23T20:05:04.733390Z",
     "shell.execute_reply.started": "2025-03-23T20:04:31.471149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_histogram(photo_dataset, title='sample photos')\n",
    "plot_histogram(monet_dataset, title='Monet paintings')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the EDA is done, we set the batch size of the dataset for training.\n",
    "\n",
    "Below mostly from https://www.tensorflow.org/datasets/performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.371037Z",
     "iopub.status.idle": "2025-03-23T18:10:53.371320Z",
     "shell.execute_reply": "2025-03-23T18:10:53.371195Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.371181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# # ds = ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# monet_dataset = monet_dataset.cache()\n",
    "# # For true randomness, we set the shuffle buffer to the full dataset size.\n",
    "# monet_dataset = monet_dataset.shuffle(number_of_monets*100).repeat(100)\n",
    "# # Batch after shuffling to get unique batches at each epoch.\n",
    "# monet_dataset = monet_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "# monet_dataset = monet_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# .shuffle(10000, reshuffle_each_iteration=True).repeat(repeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture (25 pts)\n",
    "\n",
    "*Describe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem.*\n",
    "\n",
    "### Discriminator\n",
    "Source: https://keras.io/examples/generative/dcgan_overriding_train_step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.372373Z",
     "iopub.status.idle": "2025-03-23T18:10:53.372815Z",
     "shell.execute_reply": "2025-03-23T18:10:53.372602Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.372580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "my_discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(256, 256, 3)),\n",
    "        layers.Conv2D(int(64), kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(int(128), kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(int(128), kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "my_discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.374220Z",
     "iopub.status.idle": "2025-03-23T18:10:53.374660Z",
     "shell.execute_reply": "2025-03-23T18:10:53.374456Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.374436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    my_discriminator2 = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(256, 256, 3)),\n",
    "            layers.Conv2D(int(32), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(int(64), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(int(128), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(int(256), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(int(512), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"discriminator\",\n",
    "    )\n",
    "    my_discriminator2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "\n",
    "Source: https://keras.io/examples/generative/dcgan_overriding_train_step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.375904Z",
     "iopub.status.idle": "2025-03-23T18:10:53.376361Z",
     "shell.execute_reply": "2025-03-23T18:10:53.376159Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.376139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    latent_dim = 100\n",
    "    my_generator = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            layers.Dense(8 * 8 * 128),\n",
    "            layers.Reshape((8, 8, 128)),\n",
    "            layers.Conv2DTranspose(int(128), kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(int(256), kernel_size=4, strides=4, padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(int(512), kernel_size=4, strides=4, padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"generator\",\n",
    "    )\n",
    "    my_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.377361Z",
     "iopub.status.idle": "2025-03-23T18:10:53.377797Z",
     "shell.execute_reply": "2025-03-23T18:10:53.377584Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.377562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    latent_dim = 100\n",
    "    my_generator2 = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            layers.Dense(16 * 16 * 512),\n",
    "            layers.Reshape((16, 16, 512)),\n",
    "            layers.Conv2DTranspose(int(256), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(int(128), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(int(64), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(int(32), kernel_size=3, strides=2, padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"tanh\"),\n",
    "        ],\n",
    "        name=\"generator\",\n",
    "    )\n",
    "    my_generator2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Sources: \n",
    "https://www.kaggle.com/code/thuylinh225/generate-monet-images-using-dcgan\n",
    "https://keras.io/examples/generative/dcgan_overriding_train_step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.379661Z",
     "iopub.status.idle": "2025-03-23T18:10:53.379983Z",
     "shell.execute_reply": "2025-03-23T18:10:53.379820Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.379806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create loss function for the generator\n",
    "with strategy.scope():\n",
    "    def generator_loss(fake_output):\n",
    "        # cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    # create loss function for the discriminator\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        # cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "\n",
    "Source: https://keras.io/examples/generative/dcgan_overriding_train_step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.381229Z",
     "iopub.status.idle": "2025-03-23T18:10:53.381662Z",
     "shell.execute_reply": "2025-03-23T18:10:53.381458Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.381437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create two separate optimizers for the generator and discriminator\n",
    "with strategy.scope():\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.382897Z",
     "iopub.status.idle": "2025-03-23T18:10:53.383217Z",
     "shell.execute_reply": "2025-03-23T18:10:53.383089Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.383075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters to be used for training\n",
    "EPOCHS = 201\n",
    "BATCH_SIZE = 32\n",
    "noise_dim = 100\n",
    "shape_dim = [256,256,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.384412Z",
     "iopub.status.idle": "2025-03-23T18:10:53.384862Z",
     "shell.execute_reply": "2025-03-23T18:10:53.384641Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.384620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DCGAN_model:\n",
    "    def __init__(self, noise_dim, EPOCHS, BATCH_SIZE, generator, discriminator, dataset):  \n",
    "        self.noise_dim = noise_dim\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, images):\n",
    "    \n",
    "    # Create random noise vector\n",
    "        noise = tf.random.normal([images.shape[0], noise_dim])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        # generate images use random noise vector\n",
    "            generated_images = self.generator(noise, training=True)\n",
    "\n",
    "            # use discriminator to evaluate the real and fake images\n",
    "            real_output = self.discriminator(images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "            # compute generator loss and discriminator loss\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "            # Compute gradients\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "            # Update optimizers\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return (gen_loss + disc_loss) * 0.5\n",
    "    \n",
    "    @tf.function\n",
    "    def distributed_train(self, images):\n",
    "        per_replica_losses = strategy.run(self.train, args=(images,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
    "    \n",
    "    def generate_images(self):\n",
    "        noise = tf.random.normal([self.BATCH_SIZE, self.noise_dim]) \n",
    "        predictions = self.generator.predict(noise)\n",
    "        return predictions\n",
    "        \n",
    "    def generate_and_plot_images(self):      \n",
    "        image = self.generate_images()\n",
    "        gen_imgs = 0.5 * image + 0.5\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            plt.imshow(gen_imgs[i, :, :, :])\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def train_loop(self):\n",
    "        e_ls = []\n",
    "        mean_ls = []\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            start = time.time()\n",
    "            print('Epoch:', epoch+1, end='\\r')\n",
    "\n",
    "            total_loss = 0.0\n",
    "            num_batches = 0\n",
    "\n",
    "            for image_batch in self.dataset:\n",
    "                loss = self.distributed_train(image_batch['image'])\n",
    "                total_loss += tf.reduce_mean(loss)\n",
    "                num_batches += 1\n",
    "            mean_loss = total_loss / num_batches\n",
    "\n",
    "            if (epoch+1) % 200 == 0:                                  \n",
    "                print ('Time for epoch {} is {} sec, mean loss is {}'.format(epoch + 1, time.time()-start, mean_loss))\n",
    "                self.generate_and_plot_images()\n",
    "                \n",
    "                e_ls.append(epoch+1)\n",
    "                mean_ls.append(mean_loss)\n",
    "        print(\"\\nMean Loss for every 200 epochs: \\n\")\n",
    "        table = pd.DataFrame({\"Epoch\": e_ls, \"Mean Loss\": np.array(mean_ls)})\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Override the train step.\n",
    "\n",
    "Source: https://keras.io/examples/generative/dcgan_overriding_train_step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T18:10:53.386633Z",
     "iopub.status.idle": "2025-03-23T18:10:53.386982Z",
     "shell.execute_reply": "2025-03-23T18:10:53.386811Z",
     "shell.execute_reply.started": "2025-03-23T18:10:53.386796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train, visualize and print out the result for DCGAN model\n",
    "gan1 = DCGAN_model(noise_dim, EPOCHS, BATCH_SIZE, my_generator2, my_discriminator2, monet_dataset)\n",
    "res1 = gan1.train_loop()\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis (35 pts)\n",
    "\n",
    "*Run hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.*\n",
    "\n",
    "*Includes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion (15 pts)\n",
    "\n",
    "*Discuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial\n",
    "https://keras.io/examples/generative/dcgan_overriding_train_step\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30299,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
